{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left;\">\n",
    "<table style=\"width:100%; background-color:transparent;\">\n",
    "  <tr style=\"background-color:transparent;\">\n",
    "    <td align=\"center\"; style=\"background-color:transparent;\"><a href = \"https://joliot.cea.fr/drf/joliot/recherche/neurospin\"><img src=\"https://baobablab.github.io/bhb/images/collaborators/cea.jpg\" width=\"35%\"></td>\n",
    "    <td align=\"center\"; style=\"background-color:transparent; width: 50%;\"><a href = \"https://dataia.eu/\"><img src=\"https://github.com/ramp-kits/brain_age_with_site_removal/raw/main/DATAIA-h.png\" width=\"80%\"></a></td>\n",
    "  </tr>\n",
    "</table> \n",
    "</div>\n",
    "\n",
    "<center><h1>OpenBHB challenge: predicting brain age with site-effect removal</h1></center>\n",
    "\n",
    "<center><h3>A data challenge on Healthy Controls</h3></center>\n",
    "\n",
    "<center><i>Antoine Grigis, Benoît Dufumier, Edouard Duchesnay (Université Paris-Saclay, CEA, NeuroSpin), François Caud, Alexandre Gramfort (Université Paris-Saclay, DATAIA) </i></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To download and run this notebook**: download the [full starting kit](https://github.com/ramp-kits/brain_age_with_site_removal), with all the necessary files.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Software\n",
    "\n",
    "This starting kit requires Python 3 and the following dependencies:\n",
    "\n",
    "* `numpy`\n",
    "* `scipy`\n",
    "* `nibabel`\n",
    "* `pandas`\n",
    "* `scikit-learn`\n",
    "* `nilearn`\n",
    "* `matplolib`\n",
    "* `seaborn`\n",
    "* `jupyter`\n",
    "* `progressbar`\n",
    "* `torch`\n",
    "* `ramp-workflow`\n",
    "\n",
    "You can install the dependencies using `pip` with the following command-line:\n",
    "\n",
    "```\n",
    "pip install -U -r requirements.txt\n",
    "```\n",
    "\n",
    "If you are using `conda`, we provide an `environment.yml` file for similar usage:\n",
    "\n",
    "```\n",
    "conda env create -n ramp-brainage-siterm -f environment.yml\n",
    "```\n",
    "\n",
    "Then, you can activate/desactivate the conda environment using:\n",
    "\n",
    "```\n",
    "conda activate ramp-brainage-siterm\n",
    "conda deactivate\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction: what is this challenge about\n",
    "\n",
    "Modelling brain development and maturation in the healthy population with Machine Learning (ML) from brain MRI images is a fundamental challenge. Biological processes implied are complex and highly heterogeneous between individuals, comprising both environmental and genetic variability across subjects. As a result, there is a need for large MRI datasets including subjects with a wide range of age. However, these datasets are often multi-sites (i.e images are acquired at different hospitals or acquisition centers across the world) and it induces a strong bias in current MRI data, due to difference between scanners (magnetic field, constructor, gradients, etc.)\n",
    "\n",
    "Consequently, this challenge aims at building i) robust ML models that can accuratly predict chronological age from brain MRI while ii) removing non-biological site information from MRI images. We have designed this challenge in the context of **representation learning** and it promotes the development of new ML and **Deep Learning** algorithms.\n",
    "\n",
    "More specifically, aging is associated with grey matter (GM) atrophy. Each year, an adult lose 0.1% of GM. We will try to learn a predictor of the chronological age (true age) using GM derived features on a population of healthy control participants.\n",
    "\n",
    "Such a predictor provides the expected **brain age** of a subject. Deviation from this expected brain age indicates acceleration or slowdown of the aging process which may be associated with a pathological neurobiological process or protective factor of aging.\n",
    "\n",
    "The dataset is composed of images coming from various sites, different MRI scanners and acquired under various settings. In order to predict properly the age of participants, one should deal with the **site/scanner effect**.\n",
    "\n",
    "**Objective:** the models submitted to this challenge must encode the data (i.e. perform dimensionality reduction) such that all biological age features are retained while scanner/acquisition protocol information are removed from the resulting encoded data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data\n",
    "\n",
    "We propose to use the [openBHB dataset](https://baobablab.github.io/bhb/dataset). This dataset is composed of 3227 training images, 757 validation images (available from command line with `download_data.py` or from [IEEE Dataport](https://ieee-dataport.org/open-access/openbhb-multi-site-brain-mri-dataset-age-prediction-and-debiasing)) and 664 testing images (kept private). The validation set is composed of 2 subsets: an internal set (with images acquired from the same MRI scanners as training images); and an external set (with images acquired with different scanners/protocols as training images). It is used for local testing/debugging (e.g. using `ramp-test`, see below) or for cross-validating hyper-parameters of your model.\n",
    "\n",
    "### Input data\n",
    "\n",
    "All data have been preprocessed uniformly and checked. The dataset is composed of T1w images derived features composed of Quasi-Raw, CAT12 VBM, and FreeSurfer:\n",
    "\n",
    "- Quasi-Raw: minimally preprocessed data were generated using [ANTS bias field correction](https://manpages.debian.org/testing/ants/N4BiasFieldCorrection.1.en.html), [FSL FLIRT](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FLIRT) affine registration with 9 degrees of freedom (no shearing) to the isotropic 1mm MNI template, and the application of a brain mask to remove non-brain tissues in the final images.\n",
    "\n",
    "- CAT12 VBM: Voxel-Based Morphometry (VBM) was performed with [CAT12](http://www.neuro.uni-jena.de/cat). The analysis stream includes non-linear spatial registration to the isotropic 1.5mm MNI template, Gray Matter (GM), White Matter (WM), and CerebroSpinal Fluid (CSF) tissues segmentation, bias correction of intensity non-uniformities, and segmentations modulation by scaling with the amount of volume changes due to spatial registration. VBM is most often applied to investigate the GM. The sensitivity of VBM in the WM is low, and usually, diffusion-weighted imaging is preferred for that purpose. For this reason, only the modulated GM images are shared. Moreover, CAT12 computes GM volumes averaged on the Neuromorphometrics atlas that includes 284 brain cortical and sub-cortical ROIs.\n",
    "\n",
    "- FreeSurfer: Cortical analysis was performed with [FreeSurfer \"recon-all\"](https://surfer.nmr.mgh.harvard.edu). The analysis stream includes intensity normalization, skull stripping, segmentation of GM (pial) and WM, hemispheric-based tessellations, topology corrections and inflation, and registration to the **fsaverage** template. From the available morphological measures, the Desikan (68 regions) and Destrieux (148 regions) ROI-based surface area, GM volume, average thickness, thickness standard deviation, integrated rectified mean curvature, integrated rectified gaussian curvature, and intrinsic curvature are computed. The desikan parcellation, the cortical curvature, sulcal indices, and thickness are also available on a ico7 left/right symmetrized mesh with (163842 vertives) derived using FreeSurfer-Xhemi.\n",
    "\n",
    "The `problem.get_[train|test]_data()` function returns a big matrix of shape $n_{subjects}\\times n_{features}$. The features are the concatenation of all modalities: CAT12 VBM (519945 features), Quasi-Raw (1827095 features), FreeSurfer-Xhemi 4 x 2 (left and right hemispheres) channels | 163842 vertices (ico7), CAT12 VBM 284 ROIs (284 features), FreeSurfer Desikan 7 channels | 68 ROIs (476 features), and FreeSurfer 7 channels | 148 ROIs (1036 features)  data leading to a $n_{subjects} \\times 3659572$ array. For ROI-based data, the channel and ROI dimensions has been flattened, and for image-based data a GM (for CAT12 VBM) or brain (for Quasi-Raw) mask has been applied using `nilearn.masking.apply_mask`.\n",
    "\n",
    "A `FeatureExtractor` class is proposed in the `submissions/starting_kit/estimator.py` file that simplify the access of each data bloc. Below you will find some use cases of this functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-15T12:21:31.087629Z",
     "start_time": "2023-06-15T12:21:29.165247Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of selected features (1, 1, 121, 145, 121)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from submissions.starting_kit.estimator import FeatureExtractor\n",
    "\n",
    "# Need to specify where to find the brain and GM masks using env variables.\n",
    "os.environ[\"VBM_MASK\"] = \"./cat12vbm_space-MNI152_desc-gm_TPM.nii.gz\"\n",
    "os.environ[\"QUASIRAW_MASK\"] = \"./quasiraw_space-MNI152_desc-brain_T1w.nii.gz\"\n",
    "\n",
    "X_flat = np.zeros((1, 2512678), dtype=np.single)\n",
    "X = FeatureExtractor(dtype=\"vbm\").transform(X_flat)\n",
    "print(\"Shape of selected features\", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Remark:** `problem.get_test_data()` returns locally (on your computer) the official validation set for this challenge."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target labels\n",
    "\n",
    "The `problem.get_[train|test]_data()` function returns as second element the target vector composed of `age` and `site` information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-15T12:42:49.788706Z",
     "start_time": "2023-06-15T12:42:49.522775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[38;5;178m\u001B[1mRead TRAIN...\u001B[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "mmap length is greater than file size",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m get_ipython()\u001B[38;5;241m.\u001B[39mrun_line_magic(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmatplotlib\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minline\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mproblem\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_train_data, DatasetHelper\n\u001B[0;32m----> 4\u001B[0m train_dataset \u001B[38;5;241m=\u001B[39m \u001B[43mDatasetHelper\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_loader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mget_train_data\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m X_train, y_train \u001B[38;5;241m=\u001B[39m train_dataset\u001B[38;5;241m.\u001B[39mget_data()\n\u001B[1;32m      6\u001B[0m df_labels_train \u001B[38;5;241m=\u001B[39m train_dataset\u001B[38;5;241m.\u001B[39mlabels_to_dataframe()\n",
      "File \u001B[0;32m~/PycharmProjects/brain_age_with_site_removal/problem.py:717\u001B[0m, in \u001B[0;36mDatasetHelper.__init__\u001B[0;34m(self, data_loader)\u001B[0m\n\u001B[1;32m    716\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, data_loader):\n\u001B[0;32m--> 717\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mX, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39my \u001B[38;5;241m=\u001B[39m \u001B[43mdata_loader\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    718\u001B[0m     memory \u001B[38;5;241m=\u001B[39m get_memory()\n\u001B[1;32m    719\u001B[0m     size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39my)\n",
      "File \u001B[0;32m~/PycharmProjects/brain_age_with_site_removal/problem.py:586\u001B[0m, in \u001B[0;36mget_train_data\u001B[0;34m(path)\u001B[0m\n\u001B[1;32m    583\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_train_data\u001B[39m(path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    584\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\" Get openBHB public train set.\u001B[39;00m\n\u001B[1;32m    585\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 586\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtrain\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/brain_age_with_site_removal/problem.py:527\u001B[0m, in \u001B[0;36m_read_data\u001B[0;34m(path, dataset)\u001B[0m\n\u001B[1;32m    525\u001B[0m     df\u001B[38;5;241m.\u001B[39mloc[df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msplit\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexternal_test\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msite\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mnan\n\u001B[1;32m    526\u001B[0m     y_arr \u001B[38;5;241m=\u001B[39m df[[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mage\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msite\u001B[39m\u001B[38;5;124m\"\u001B[39m]]\u001B[38;5;241m.\u001B[39mvalues\n\u001B[0;32m--> 527\u001B[0m     x_arr \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdata\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m.npy\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    528\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mmmap_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    529\u001B[0m     split \u001B[38;5;241m=\u001B[39m df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msplit\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mvalues\u001B[38;5;241m.\u001B[39mtolist()\n\u001B[1;32m    530\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m- y size [original]:\u001B[39m\u001B[38;5;124m\"\u001B[39m, y_arr\u001B[38;5;241m.\u001B[39mshape)\n",
      "File \u001B[0;32m~/anaconda3/envs/ramp-brainage-siterm/lib/python3.10/site-packages/numpy/lib/npyio.py:429\u001B[0m, in \u001B[0;36mload\u001B[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001B[0m\n\u001B[1;32m    427\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m allow_pickle:\n\u001B[1;32m    428\u001B[0m         max_header_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m64\u001B[39m\n\u001B[0;32m--> 429\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mformat\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen_memmap\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmmap_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    430\u001B[0m \u001B[43m                              \u001B[49m\u001B[43mmax_header_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_header_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    431\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    432\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mformat\u001B[39m\u001B[38;5;241m.\u001B[39mread_array(fid, allow_pickle\u001B[38;5;241m=\u001B[39mallow_pickle,\n\u001B[1;32m    433\u001B[0m                              pickle_kwargs\u001B[38;5;241m=\u001B[39mpickle_kwargs,\n\u001B[1;32m    434\u001B[0m                              max_header_size\u001B[38;5;241m=\u001B[39mmax_header_size)\n",
      "File \u001B[0;32m~/anaconda3/envs/ramp-brainage-siterm/lib/python3.10/site-packages/numpy/lib/format.py:937\u001B[0m, in \u001B[0;36mopen_memmap\u001B[0;34m(filename, mode, dtype, shape, fortran_order, version, max_header_size)\u001B[0m\n\u001B[1;32m    934\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mw+\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    935\u001B[0m     mode \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr+\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m--> 937\u001B[0m marray \u001B[38;5;241m=\u001B[39m \u001B[43mnumpy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmemmap\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshape\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    938\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moffset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moffset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    940\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m marray\n",
      "File \u001B[0;32m~/anaconda3/envs/ramp-brainage-siterm/lib/python3.10/site-packages/numpy/core/memmap.py:267\u001B[0m, in \u001B[0;36mmemmap.__new__\u001B[0;34m(subtype, filename, dtype, mode, offset, shape, order)\u001B[0m\n\u001B[1;32m    265\u001B[0m \u001B[38;5;28mbytes\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m start\n\u001B[1;32m    266\u001B[0m array_offset \u001B[38;5;241m=\u001B[39m offset \u001B[38;5;241m-\u001B[39m start\n\u001B[0;32m--> 267\u001B[0m mm \u001B[38;5;241m=\u001B[39m \u001B[43mmmap\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmmap\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfid\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfileno\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mbytes\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccess\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43macc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moffset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstart\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    269\u001B[0m \u001B[38;5;28mself\u001B[39m \u001B[38;5;241m=\u001B[39m ndarray\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__new__\u001B[39m(subtype, shape, dtype\u001B[38;5;241m=\u001B[39mdescr, buffer\u001B[38;5;241m=\u001B[39mmm,\n\u001B[1;32m    270\u001B[0m                        offset\u001B[38;5;241m=\u001B[39marray_offset, order\u001B[38;5;241m=\u001B[39morder)\n\u001B[1;32m    271\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_mmap \u001B[38;5;241m=\u001B[39m mm\n",
      "\u001B[0;31mValueError\u001B[0m: mmap length is greater than file size"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from problem import get_train_data, DatasetHelper\n",
    "\n",
    "train_dataset = DatasetHelper(data_loader=get_train_data)\n",
    "X_train, y_train = train_dataset.get_data()\n",
    "df_labels_train = train_dataset.labels_to_dataframe()\n",
    "print(df_labels_train.head())\n",
    "print(df_labels_train.describe(include=(float, )))\n",
    "for dtype in (\"vbm\", \"quasiraw\", \"xhemi\"):\n",
    "    X_select_train = FeatureExtractor(dtype=dtype).transform(X_train[:10])\n",
    "    print(\"Shape of data & selected features:\", X_train.shape,\n",
    "          X_select_train.shape)\n",
    "    print(train_dataset.get_channels_info(X_select_train))\n",
    "    train_dataset.plot_data(X_select_train, sample_id=0, channel_id=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge Ranking and Evaluation metrics\n",
    "\n",
    "In the context of representation learning, we perform **linear probing** to evaluate a model submitted on RAMP. Specifically, on the RAMP server, the public data-sets (training+validation) and private testing data (including internal and external subsets, see above) are encoded by the trained model, i.e all data are passed through the model. The resulting output vectors are stacked to build 3 matrices: $X_{train}\\in \\mathbb{R}^{n_{train}\\times p}$ (public training+validation sets encoded), $X_{test}^{int}\\in \\mathbb{R}^{n_{test}\\times p}$ (private internal test encoded), $X_{test}^{ext}\\in \\mathbb{R}^{n_{test}'\\times p}$ (private external test encoded). $p<10^4$ is the model's output dimension (a.k.a latent space dimension). Both training+validation and *internal* test are stratified on both age, sex and **site** (i.e they contain the same sites with similar age and sex distributions). However, the *external* test contains acquisition **sites independent**from the public data-sets.\n",
    "\n",
    "*Note:* we usually call $X_{train}, X_{test}^{int}, X_{test}^{ext}$ the model **representation**\n",
    "\n",
    "After encoding, a simple linear Ridge regression is trained on $X_{train}$ and tested on $X_{test}^{int}$ and $X_{test}^{int}$ to predict age. The final Mean Absolute Error (MAE, the lower the better) is computed as the reference metric for age prediction and 2 final scores are computed: MAE(internal), computed on $X_{test}^{int}$, and MAE(external), computed on $X_{test}^{ext}$. As for site prediction, a linear logistic regression is also trained on $X_{train}$ and tested on $X_{test}^{int}$, $X_{test}^{ext}$. The final Balanced Accuracy (BAcc) is computed and serves as reference score for site prediction. Bacc should be **equal to random chance** in this challenge, that is $1/n_{sites}=1/64\\approx1.56\\%$ because we want the representation $X_{train}$ to *remove* site information from MRI images.\n",
    "\n",
    "All models are ranked according to a combination of the 3 metrics: MAE(internal), MAE(external) and Bacc(sites). The official leaderboard can be find [here](https://baobablab.github.io/bhb/challenges/age_prediction_with_site_removal).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting to the online challenge: [ramp.studio](http://ramp.studio)\n",
    "\n",
    "### Online submission\n",
    "\n",
    "Once you found a good model, you can submit them to [ramp.studio](http://www.ramp.studio) to enter the online challenge. First, if it is your first time using the RAMP platform, [sign up](http://www.ramp.studio/sign_up), otherwise [log in](http://www.ramp.studio/login). Then sign up to the event [brain_age_with_site_removal](http://www.ramp.studio/events/brain_age_with_site_removal). Sign up for the event. Both signups are controled by RAMP administrators, so there **can be a delay between asking for signup and being able to submit**.\n",
    "\n",
    "Once your signup request is accepted, you can go to your [sandbox](http://www.ramp.studio/events/brain_age_with_site_removal/sandbox) and copy-paste or upload. You can also create a new starting-kit in the `submissions` folder containing these three files `estimator.py`, `weights.pth` and `metadata.pkl` and upload those file directly. You can check the starting-kit ([`estimator.py`](https://github.com/ramp-kits/brain_age_with_site_removal/submissions/starting_kit/estimator.py)) for an example. The submission is only tested on our backend in the similar way as `ramp_test_submission` does it locally. That is the reason why the weights of the trained model needs to be uploaded. Moreover extra info/data can be provided in the metadata pickle file. It may enable to restore the scaler used during the training.\n",
    "\n",
    "### Official leaderboard\n",
    "\n",
    "While your submission is waiting in the queue and being trained, you can find it in the \"New submissions (pending training)\" table in [my submissions](http://www.ramp.studio/events/brain_age_with_site_removal/my_submissions). Once it is trained, you get a mail, and your submission shows up on the [official leaderboard](https://baobablab.github.io/bhb/challenges/age_prediction_with_site_removal) that is refreshed everyday.\n",
    "If there is an error (despite having tested your submission locally with `ramp-test`, see below), it will show up in the \"Failed submissions\" table in [my submissions](http://www.ramp.studio/events/brain_age_with_site_removal/my_submissions). You can click on the error to see part of the trace.\n",
    "\n",
    "Since the test set used on RAMP is private and with acquisition scanners/protocols different from the training/validation set, the scores obtained may be different from what you have locally on the validation set.\n",
    "\n",
    "### Local test and Debugging\n",
    "\n",
    "Once you have cloned the Github repository <https://github.com/ramp-kits/brain_age_with_site_removal> you can test your model locally (on your computer) to debug and evaluate your model's performance.\n",
    "\n",
    "Each submission needs to be in a new folder located in the `submissions` directory. For instance, to create a `linear_regression_rois` submission, you can copy the `starting_kit` with:\n",
    "\n",
    "```\n",
    "cp -r submissions/strating_kit submissions/linear_regression_rois\n",
    "```\n",
    "\n",
    "Now, you have the 3 mandatory files created for a new submission (`estimator.py`, `weights.pth`, `metadata.pkl`) inside `submissions/linear_regression_rois` that you can customize. In particular, `estimator.py` must contain a function `get_estimator()` that returns a scikit-learn Pipeline (with `fit()` and `predict()` implemented). Once you have customized your estimator, weights and metadata, you can perform a local test with:\n",
    "\n",
    "```\n",
    "ramp-test --submission linear_regression_rois [--quick-test]\n",
    "```\n",
    "\n",
    "**Warning:** the data need to be downloaded beforehand using `download_data.py` script. It can take some time and about 55GB of disk memory. If you only want to perform a quick check with random data, you can use the option `--quick-test`.\n",
    "\n",
    "*Note:* model weights are expected in a file called `weights.pth` located in your submission folder `submissions/linear_regression_rois`. Extra information/data can also be loaded from `metadata.pkl` file using **read_pickle()** from Pandas library (it can be useful de define a standardizer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where to start: a simple MLP\n",
    "\n",
    "We give a quick example of how to train a simple Multi-Layers Perceptron (MLP) using PyTorch on one modality (cortical thickness with Desikan atlas). The model's weights can be saved to `weights.pth` and a new submission can be created following the steps described previously.\n",
    "\n",
    "### Data downloading\n",
    "\n",
    "We start by downloading the data from the internet using the following command-line:\n",
    "\n",
    "```\n",
    "python download_data.py\n",
    "```\n",
    "\n",
    "The train/validation data will be available in the `data` directory. This download step can be long. We also provide a way to create a small random dataset enabling the `--test` option of the script:\n",
    "\n",
    "```\n",
    "python download_data.py --test\n",
    "```\n",
    "\n",
    "In the rest of this notebook we will use this random dataset. We will train a MLP on the average cortical thickness (channel 2) defined from the Desikan parcellation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[38;5;178m\u001B[1mRead TRAIN...\u001B[0m\n",
      "Shape of data & selected features: (20, 3659572) (20, 7, 68)\n",
      "                                        channels\n",
      "0                              surface_area_mm^2\n",
      "1                        gray_matter_volume_mm^3\n",
      "2                           average_thickness_mm\n",
      "3                            thickness_stddev_mm\n",
      "4      integrated_rectified_mean_curvature_mm^-1\n",
      "5  integrated_rectified_gaussian_curvature_mm^-2\n",
      "6                      intrinsic_curvature_index\n",
      "    lh-bankssts  lh-caudalanteriorcingulate  lh-caudalmiddlefrontal  \\\n",
      "0         2.695                       2.367                   2.569   \n",
      "1         2.516                       2.354                   2.706   \n",
      "2         2.616                       2.348                   2.577   \n",
      "3         2.697                       2.686                   2.651   \n",
      "4         2.204                       2.322                   2.492   \n",
      "5         2.357                       2.360                   2.726   \n",
      "6         2.497                       2.311                   2.378   \n",
      "7         2.206                       2.851                   2.781   \n",
      "8         2.606                       2.578                   2.511   \n",
      "9         2.297                       2.661                   2.419   \n",
      "10        2.465                       2.674                   2.258   \n",
      "11        2.221                       2.379                   2.613   \n",
      "12        2.526                       2.279                   2.530   \n",
      "13        2.735                       2.550                   2.664   \n",
      "14        2.552                       2.194                   2.728   \n",
      "15        2.382                       2.454                   2.599   \n",
      "16        2.148                       2.463                   2.590   \n",
      "17        2.373                       2.905                   2.589   \n",
      "18        2.462                       2.383                   2.545   \n",
      "19        2.860                       2.841                   2.546   \n",
      "\n",
      "    lh-cuneus  lh-entorhinal  lh-fusiform  lh-inferiorparietal  \\\n",
      "0       2.103          3.091        2.850                2.568   \n",
      "1       1.872          3.183        2.767                2.322   \n",
      "2       1.980          3.105        2.660                2.573   \n",
      "3       2.109          3.656        2.895                2.623   \n",
      "4       1.780          3.261        2.473                2.126   \n",
      "5       1.689          3.209        2.824                2.414   \n",
      "6       1.872          3.200        2.506                2.183   \n",
      "7       2.044          2.902        2.852                2.469   \n",
      "8       1.921          3.466        2.768                2.448   \n",
      "9       1.822          3.248        2.589                2.237   \n",
      "10      1.965          2.392        2.676                2.478   \n",
      "11      1.702          3.395        2.593                2.518   \n",
      "12      1.717          3.442        2.695                2.370   \n",
      "13      1.979          3.639        2.744                2.640   \n",
      "14      1.873          3.375        2.602                2.353   \n",
      "15      1.837          3.066        2.609                2.366   \n",
      "16      2.100          3.530        2.611                2.330   \n",
      "17      1.798          3.063        2.622                2.430   \n",
      "18      1.811          3.617        2.683                2.233   \n",
      "19      2.041          3.240        2.823                2.551   \n",
      "\n",
      "    lh-inferiortemporal  lh-isthmuscingulate  lh-lateraloccipital  ...  \\\n",
      "0                 2.830                2.173                2.287  ...   \n",
      "1                 2.954                2.374                2.077  ...   \n",
      "2                 2.648                2.410                2.227  ...   \n",
      "3                 2.974                2.446                2.267  ...   \n",
      "4                 2.927                2.190                2.157  ...   \n",
      "5                 2.805                2.228                2.023  ...   \n",
      "6                 2.569                2.391                1.934  ...   \n",
      "7                 2.849                2.322                2.321  ...   \n",
      "8                 2.932                2.347                2.200  ...   \n",
      "9                 2.743                2.363                2.075  ...   \n",
      "10                2.736                2.514                2.191  ...   \n",
      "11                2.789                2.300                2.171  ...   \n",
      "12                2.671                2.068                2.034  ...   \n",
      "13                3.012                2.111                2.333  ...   \n",
      "14                2.820                2.335                2.183  ...   \n",
      "15                2.538                2.248                2.034  ...   \n",
      "16                2.744                2.542                2.168  ...   \n",
      "17                2.550                2.201                2.010  ...   \n",
      "18                2.718                2.343                2.072  ...   \n",
      "19                2.980                2.476                2.286  ...   \n",
      "\n",
      "    rh-rostralanteriorcingulate  rh-rostralmiddlefrontal  rh-superiorfrontal  \\\n",
      "0                         2.663                    2.392               2.736   \n",
      "1                         2.820                    2.205               2.682   \n",
      "2                         2.726                    2.280               2.761   \n",
      "3                         2.697                    2.477               2.769   \n",
      "4                         2.874                    2.157               2.583   \n",
      "5                         3.006                    2.434               2.778   \n",
      "6                         2.661                    2.169               2.831   \n",
      "7                         2.295                    2.450               2.797   \n",
      "8                         2.533                    2.148               2.592   \n",
      "9                         2.673                    2.224               2.647   \n",
      "10                        3.081                    2.279               2.522   \n",
      "11                        2.808                    2.414               2.886   \n",
      "12                        2.641                    2.366               2.763   \n",
      "13                        2.568                    2.406               2.867   \n",
      "14                        2.671                    2.211               2.724   \n",
      "15                        2.737                    2.052               2.611   \n",
      "16                        2.549                    2.421               2.919   \n",
      "17                        2.940                    2.484               2.783   \n",
      "18                        3.029                    2.377               2.638   \n",
      "19                        2.957                    2.555               2.875   \n",
      "\n",
      "    rh-superiorparietal  rh-superiortemporal  rh-supramarginal  \\\n",
      "0                 2.329                2.998             2.716   \n",
      "1                 2.069                2.948             2.453   \n",
      "2                 2.319                2.788             2.614   \n",
      "3                 2.385                3.074             2.624   \n",
      "4                 2.104                2.983             2.380   \n",
      "5                 2.183                2.973             2.535   \n",
      "6                 2.050                2.729             2.377   \n",
      "7                 2.286                2.704             2.522   \n",
      "8                 2.248                2.978             2.689   \n",
      "9                 2.108                2.808             2.470   \n",
      "10                2.282                2.691             2.372   \n",
      "11                2.187                2.952             2.656   \n",
      "12                2.187                2.679             2.545   \n",
      "13                2.496                2.977             2.733   \n",
      "14                2.131                2.809             2.451   \n",
      "15                2.093                2.649             2.416   \n",
      "16                2.305                2.633             2.387   \n",
      "17                2.169                2.818             2.663   \n",
      "18                2.015                2.849             2.370   \n",
      "19                2.247                3.110             2.688   \n",
      "\n",
      "    rh-frontalpole  rh-temporalpole  rh-transversetemporal  rh-insula  \n",
      "0            2.961            3.722                  2.826      2.874  \n",
      "1            2.684            3.631                  2.653      2.954  \n",
      "2            2.604            2.870                  2.835      2.904  \n",
      "3            2.803            3.736                  2.724      3.078  \n",
      "4            2.454            3.766                  2.754      2.985  \n",
      "5            2.695            3.297                  2.751      2.985  \n",
      "6            2.373            3.551                  2.055      2.940  \n",
      "7            2.476            3.318                  2.348      3.093  \n",
      "8            2.842            4.137                  2.530      2.983  \n",
      "9            2.604            3.794                  2.259      3.100  \n",
      "10           2.566            2.859                  2.717      3.184  \n",
      "11           2.837            3.847                  2.645      3.040  \n",
      "12           2.876            3.632                  2.689      3.048  \n",
      "13           3.450            3.912                  2.629      3.058  \n",
      "14           2.706            3.754                  2.496      3.117  \n",
      "15           2.490            3.448                  2.411      2.966  \n",
      "16           2.699            3.833                  2.334      3.305  \n",
      "17           2.954            3.617                  2.260      3.080  \n",
      "18           2.889            3.725                  2.506      3.217  \n",
      "19           2.961            3.322                  2.273      3.295  \n",
      "\n",
      "[20 rows x 68 columns]\n",
      "\u001B[38;5;178m\u001B[1mRead TEST...\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 3659572) (10, 7, 68)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.realpath(\"submissions/starting_kit\"))\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from joblib.externals.loky.backend.context import get_context\n",
    "from problem import get_train_data, get_test_data, get_cv, DatasetHelper\n",
    "from estimator import FeatureExtractor\n",
    "\n",
    "# TODO: we selected only few (20) subjects for deployment speedup.\n",
    "os.environ[\"RAMP_BRAIN_AGE_SITERM_TEST\"] = \"on\"\n",
    "train_dataset = DatasetHelper(data_loader=get_train_data)\n",
    "X_train, y_train = train_dataset.get_data()\n",
    "X_train = X_train[:20]\n",
    "y_train = y_train[:20]\n",
    "X_select_train = FeatureExtractor(dtype=\"desikan_roi\").transform(X_train)\n",
    "print(\"Shape of data & selected features:\", X_train.shape,\n",
    "      X_select_train.shape)\n",
    "print(train_dataset.get_channels_info(X_select_train))\n",
    "df_data_train = train_dataset.data_to_dataframe(X_select_train, channel_id=2)\n",
    "print(df_data_train)\n",
    "X_train = X_select_train[:, 2]\n",
    "y_train = y_train[:, 0]\n",
    "\n",
    "# TODO: we selected only few (10) subjects for deployment speedup.\n",
    "test_dataset = DatasetHelper(data_loader=get_test_data)\n",
    "X_test, y_test = test_dataset.get_data(dtype=\"internal\")\n",
    "X_test = X_test[:10]\n",
    "y_test = y_test[:10]\n",
    "X_select_test = FeatureExtractor(dtype=\"desikan_roi\").transform(X_test)\n",
    "print(X_test.shape, X_select_test.shape)\n",
    "X_test = X_select_test[:, 2]\n",
    "y_test = y_test[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom scores\n",
    "\n",
    "Let's define here some utility functions to compute scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_train_test_scores(rmse_cv_test, rmse_cv_train, r2_cv_test, r2_cv_train,\n",
    "                         y_train, y_pred_train, y_test, y_pred_test):\n",
    "    \"\"\" Compute CV score, train and test score from a cv grid search model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    rmse_cv_test : array\n",
    "        Test rmse across CV folds.\n",
    "    rmse_cv_train : array\n",
    "        Train rmse across CV folds.\n",
    "    r2_cv_test : array\n",
    "        Test R2 across CV folds.\n",
    "    r2_cv_train : array\n",
    "        Train R2 across CV folds.\n",
    "    y_train : array\n",
    "        True train values.\n",
    "    y_pred_train : array\n",
    "        Predicted train values.\n",
    "    y_test : array\n",
    "        True test values.\n",
    "    y_pred_test : array\n",
    "        Predicted test values.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    info : TYPE\n",
    "        DataFrame(r2_cv, r2_train, mae_train, mse_train).\n",
    "    \"\"\"\n",
    "    # CV scores\n",
    "    rmse_cv_test_mean, rmse_cv_test_sd = (\n",
    "        np.mean(rmse_cv_test), np.std(rmse_cv_test))\n",
    "    rmse_cv_train_mean, rmse_cv_train_sd = (\n",
    "        np.mean(rmse_cv_train), np.std(rmse_cv_train))\n",
    "\n",
    "    r2_cv_test_mean, r2_cv_test_sd = (\n",
    "        np.mean(r2_cv_test), np.std(r2_cv_test))\n",
    "    r2_cv_train_mean, r2_cv_train_sd = (\n",
    "        np.mean(r2_cv_train), np.std(r2_cv_train))\n",
    "\n",
    "    # Test scores\n",
    "    rmse_test = np.sqrt(metrics.mean_squared_error(y_test, y_pred_test))\n",
    "    r2_test = metrics.r2_score(y_test, y_pred_test)\n",
    "\n",
    "    # Train scores\n",
    "    rmse_train = np.sqrt(metrics.mean_squared_error(y_train, y_pred_train))\n",
    "    r2_train = metrics.r2_score(y_train, y_pred_train)\n",
    "\n",
    "    scores = pd.DataFrame(\n",
    "        [[rmse_cv_test_mean, rmse_cv_test_sd, rmse_cv_train_mean,\n",
    "          rmse_cv_train_sd, r2_cv_test_mean, rmse_cv_test_sd, r2_cv_train_mean,\n",
    "          r2_cv_train_sd, rmse_test, r2_test, rmse_train, r2_train]],\n",
    "        columns=(\"rmse_cv_test_mean\", \"rmse_cv_test_sd\", \"rmse_cv_train_mean\",\n",
    "                 \"rmse_cv_train_sd\", \"r2_cv_test_mean\", \"rmse_cv_test_sd\",\n",
    "                 \"r2_cv_train_mean\", \"r2_cv_train_sd\", \"rmse_test\", \"r2_test\",\n",
    "                 \"rmse_train\", \"r2_train\"))\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch model definition and training\n",
    "\n",
    "Let's design a simple MLP age predictor. The framework is evaluated with a cross-validation approach. The metrics used are the root-mean-square error (RMSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "-- training model...\n",
      "-- training model...\n",
      "{\"epoch\": 0, \"step\": 0, \"lr\": 0.0001, \"loss\": 20.002262115478516, \"time\": 6}\n",
      "{\"epoch\": 0, \"step\": 1, \"lr\": 0.0001, \"loss\": 25.005809783935547, \"time\": 6}\n",
      "{\"epoch\": 0, \"step\": 2, \"lr\": 0.0001, \"loss\": 16.81253433227539, \"time\": 6}\n",
      "{\"epoch\": 0, \"step\": 0, \"lr\": 0.0001, \"loss\": 22.64293670654297, \"time\": 6}\n",
      "{\"epoch\": 0, \"step\": 1, \"lr\": 0.0001, \"loss\": 22.579811096191406, \"time\": 6}\n",
      "{\"epoch\": 0, \"step\": 2, \"lr\": 0.0001, \"loss\": 17.968618392944336, \"time\": 6}\n",
      "{\"epoch\": 1, \"step\": 3, \"lr\": 0.0001, \"loss\": 23.7823486328125, \"time\": 12}\n",
      "{\"epoch\": 1, \"step\": 4, \"lr\": 0.0001, \"loss\": 19.67910385131836, \"time\": 12}\n",
      "{\"epoch\": 1, \"step\": 5, \"lr\": 0.0001, \"loss\": 18.279457092285156, \"time\": 12}\n",
      "{\"epoch\": 1, \"step\": 3, \"lr\": 0.0001, \"loss\": 20.949039459228516, \"time\": 12}\n",
      "{\"epoch\": 1, \"step\": 4, \"lr\": 0.0001, \"loss\": 22.038158416748047, \"time\": 12}\n",
      "{\"epoch\": 1, \"step\": 5, \"lr\": 0.0001, \"loss\": 20.128307342529297, \"time\": 12}\n",
      "{\"epoch\": 2, \"step\": 6, \"lr\": 0.0001, \"loss\": 20.95842933654785, \"time\": 18}\n",
      "{\"epoch\": 2, \"step\": 7, \"lr\": 0.0001, \"loss\": 16.362695693969727, \"time\": 18}\n",
      "{\"epoch\": 2, \"step\": 8, \"lr\": 0.0001, \"loss\": 24.344623565673828, \"time\": 18}\n",
      "{\"epoch\": 2, \"step\": 6, \"lr\": 0.0001, \"loss\": 20.143613815307617, \"time\": 19}\n",
      "{\"epoch\": 2, \"step\": 7, \"lr\": 0.0001, \"loss\": 22.7155818939209, \"time\": 19}\n",
      "{\"epoch\": 2, \"step\": 8, \"lr\": 0.0001, \"loss\": 20.18282699584961, \"time\": 19}\n",
      "-- training model...\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   2 | elapsed:   46.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   2 | elapsed:   46.4s finished\n",
      "{\"epoch\": 0, \"step\": 0, \"lr\": 0.0001, \"loss\": 23.996028900146484, \"time\": 5}\n",
      "{\"epoch\": 0, \"step\": 1, \"lr\": 0.0001, \"loss\": 21.42085838317871, \"time\": 5}\n",
      "{\"epoch\": 0, \"step\": 2, \"lr\": 0.0001, \"loss\": 20.658061981201172, \"time\": 5}\n",
      "{\"epoch\": 0, \"step\": 3, \"lr\": 0.0001, \"loss\": 15.587310791015625, \"time\": 5}\n",
      "{\"epoch\": 1, \"step\": 4, \"lr\": 0.0001, \"loss\": 19.788705825805664, \"time\": 11}\n",
      "{\"epoch\": 1, \"step\": 5, \"lr\": 0.0001, \"loss\": 21.08378028869629, \"time\": 11}\n",
      "{\"epoch\": 1, \"step\": 6, \"lr\": 0.0001, \"loss\": 20.225175857543945, \"time\": 11}\n",
      "{\"epoch\": 1, \"step\": 7, \"lr\": 0.0001, \"loss\": 20.457189559936523, \"time\": 11}\n",
      "{\"epoch\": 2, \"step\": 8, \"lr\": 0.0001, \"loss\": 17.340999603271484, \"time\": 17}\n",
      "{\"epoch\": 2, \"step\": 9, \"lr\": 0.0001, \"loss\": 21.438854217529297, \"time\": 17}\n",
      "{\"epoch\": 2, \"step\": 10, \"lr\": 0.0001, \"loss\": 19.088809967041016, \"time\": 17}\n",
      "{\"epoch\": 2, \"step\": 11, \"lr\": 0.0001, \"loss\": 23.57721519470215, \"time\": 17}\n",
      "                         0\n",
      "rmse_cv_test_mean   20.369\n",
      "rmse_cv_test_sd      0.139\n",
      "rmse_cv_train_mean  21.407\n",
      "rmse_cv_train_sd     0.132\n",
      "r2_cv_test_mean     -8.931\n",
      "rmse_cv_test_sd      0.139\n",
      "r2_cv_train_mean   -16.254\n",
      "r2_cv_train_sd       2.699\n",
      "rmse_test           27.683\n",
      "r2_test            -13.820\n",
      "rmse_train          21.071\n",
      "r2_train           -13.760\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    \"\"\" Define a simple one hidden layer MLP.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "          nn.Linear(in_features, 120),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(120, 84),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(84, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    \"\"\" A torch dataset for regression.\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y=None):\n",
    "        \"\"\" Init class.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: array-like (n_samples, n_features)\n",
    "            training data.\n",
    "        y: array-like (n_samples, ), default None\n",
    "            target values.\n",
    "        \"\"\"\n",
    "        self.X = torch.from_numpy(X)\n",
    "        if y is not None:\n",
    "            self.y = torch.from_numpy(y)\n",
    "        else:\n",
    "            self.y = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        if self.y is not None:\n",
    "            return self.X[i], self.y[i]\n",
    "        else:\n",
    "            return self.X[i]\n",
    "\n",
    "\n",
    "class RegressionModel(object):\n",
    "    \"\"\" Base class for Regression models.\n",
    "    \"\"\"\n",
    "    def __init__(self, model, batch_size=5, n_epochs=3, print_freq=1):\n",
    "        \"\"\" Init class.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model: nn.Module\n",
    "            the input model.\n",
    "        batch_size:int, default 10\n",
    "            the mini_batch size.\n",
    "        n_epochs: int, default 5\n",
    "            the number of epochs.\n",
    "        print_freq: int, default 100\n",
    "            the print frequency.\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.batch_size = batch_size\n",
    "        self.n_epochs = n_epochs\n",
    "        self.print_freq = print_freq\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\" Fit model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: array-like (n_samples, n_features)\n",
    "            training data.\n",
    "        y: array-like (n_samples, )\n",
    "            target values.\n",
    "        fold: int\n",
    "            the fold index.\n",
    "        \"\"\"\n",
    "        self.model.train()\n",
    "        self.reset_weights()\n",
    "        print(\"-- training model...\")\n",
    "        dataset = Dataset(X, y)\n",
    "        loader = torch.utils.data.DataLoader(\n",
    "            dataset, batch_size=self.batch_size, shuffle=True,\n",
    "            num_workers=1, multiprocessing_context=get_context(\"loky\"))\n",
    "        loss_function = nn.L1Loss()\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-4)\n",
    "        start_time = time.time()\n",
    "        current_loss = 0.\n",
    "        for epoch in range(self.n_epochs):\n",
    "            for step, data in enumerate(loader, start=epoch * len(loader)):\n",
    "                inputs, targets = data\n",
    "                inputs, targets = inputs.float(), targets.float()\n",
    "                targets = targets.reshape((targets.shape[0], 1))\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(inputs)\n",
    "                loss = loss_function(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                current_loss += loss.item()\n",
    "                if step % self.print_freq == 0:\n",
    "                    stats = dict(epoch=epoch, step=step,\n",
    "                                 lr=optimizer.param_groups[0][\"lr\"],\n",
    "                                 loss=loss.item(),\n",
    "                                 time=int(time.time() - start_time))\n",
    "                    print(json.dumps(stats))\n",
    "        current_loss /= (len(loader) * self.n_epochs)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\" Predict using the input model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: array-like (n_samples, n_features)\n",
    "            samples.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        C: array (n_samples, )\n",
    "            returns predicted values.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        dataset = Dataset(X)\n",
    "        testloader = torch.utils.data.DataLoader(\n",
    "            dataset, batch_size=self.batch_size, shuffle=False, num_workers=1,\n",
    "            multiprocessing_context=get_context(\"loky\"))\n",
    "        with torch.no_grad():\n",
    "            C = []\n",
    "            for i, inputs in enumerate(testloader):\n",
    "                inputs = inputs.float() \n",
    "                C.append(self.model(inputs))\n",
    "            C = torch.cat(C, dim=0)\n",
    "        return C.numpy().squeeze()\n",
    "\n",
    "    def reset_weights(self):\n",
    "        \"\"\" Reset all the weights of the model.\n",
    "        \"\"\"\n",
    "        def weight_reset(m):\n",
    "            if hasattr(m, \"reset_parameters\"):\n",
    "                m.reset_parameters()\n",
    "        self.model.apply(weight_reset)\n",
    "\n",
    "\n",
    "# CV\n",
    "cv = get_cv(X_train, y_train)\n",
    "mlp = MLP(68)\n",
    "estimator = make_pipeline(StandardScaler(), RegressionModel(mlp))\n",
    "cv_results = cross_validate(\n",
    "    estimator, X_train, y_train, scoring=[\"neg_root_mean_squared_error\", \"r2\"],\n",
    "    cv=cv, verbose=1, return_train_score=True, n_jobs=5)\n",
    "\n",
    "# Refit on all train\n",
    "estimator.fit(X_train, y_train)\n",
    "\n",
    "# Apply on test\n",
    "y_pred_train = estimator.predict(X_train)\n",
    "y_pred_test = estimator.predict(X_test)\n",
    "\n",
    "scores = cv_train_test_scores(\n",
    "    rmse_cv_test=-cv_results[\"test_neg_root_mean_squared_error\"],\n",
    "    rmse_cv_train=-cv_results[\"train_neg_root_mean_squared_error\"],\n",
    "    r2_cv_test=cv_results[\"test_r2\"],\n",
    "    r2_cv_train=cv_results[\"train_r2\"],\n",
    "    y_train=y_train, y_pred_train=y_pred_train, y_test=y_test,\n",
    "    y_pred_test=y_pred_test).T.round(3)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important notes**\n",
    "\n",
    "- We expect from the submitted models to **ouput a vector** of representation for each input data. The output vector is a representation of input data that should fully preserve chronological age information AND remove site information. The vector size should be reasonable and **must** not exceed $10^4$. An error will be raised if this condition is not met.\n",
    "- The dataset is quite large, and memory mapping is used to load the data. In order to minimize the memory footprint (and to avoid errors during the submission on RAMP), we highly recommand to apply the features extraction, data preprocessing and data scaling steps as transforms. Thus all steps will be applied on each mini-batch. A working example can be found on the [`estimator.py`](https://github.com/ramp-kits/brain_age_with_site_removal/submissions/starting_kit/estimator.py) file of the starting kit."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
